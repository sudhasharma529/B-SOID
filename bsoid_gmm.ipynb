{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bsoid_gmm.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YttriLab/B-SOID/blob/py3/bsoid_gmm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_BLfb1DdY65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This serve as a python3 notebook for Vishal and Alex to test bsoid_gmm.py\n",
        "# Once this is finished, we will move on to release the python version of bsoid\n",
        "\n",
        "# Created by Alexander Hsu and Vishal Patel\n",
        "# Date: 021920\n",
        "\n",
        "# Import necessary python packages\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_boK1sph_2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def boxcar_center(a, n):\n",
        "  a = pd.Series(a)\n",
        "  moving_avg = np.array(a.rolling(window = n).mean(center=True))\n",
        "  moving_avg[0] = sum(a[0:n-2])/3\n",
        "  moving_avg[1] = sum(a[0:n-1])/4\n",
        "  # moving_avg[len(a)-2] = sum()\n",
        "      \n",
        "  # if moving_avg \n",
        "  return moving_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA2bEKbtrjky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "f882b519-d81d-4553-e0e6-9e725d00fe6e"
      },
      "source": [
        "np.random.seed(0)\n",
        "s = pd.Series(np.random.randn(7)).round(1)\n",
        "moving_avg = np.array(s.rolling(window = 5).mean(center=True))\n",
        "print(moving_avg)\n",
        "# pd.concat([s, moving_avg.round(2)],axis=1).rename(columns = {0:'signal',1:'MA'})\n",
        "a = (np.random.randn(7))\n",
        "print(a)\n",
        "a = pd.Series(a)\n",
        "print(a)\n",
        "\n",
        "moving_avg = boxcar_center(a,5)\n",
        "print(moving_avg)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ nan  nan 1.46 0.9  1.02  nan  nan]\n",
            "[-0.15135721 -0.10321885  0.4105985   0.14404357  1.45427351  0.76103773\n",
            "  0.12167502]\n",
            "0   -0.151357\n",
            "1   -0.103219\n",
            "2    0.410599\n",
            "3    0.144044\n",
            "4    1.454274\n",
            "5    0.761038\n",
            "6    0.121675\n",
            "dtype: float64\n",
            "[0.05200748 0.0750165  0.3508679  0.53334689 0.57832566        nan\n",
            "        nan]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAO5oADBdu5I",
        "colab_type": "code",
        "outputId": "129de15f-539a-4322-cafd-1f2495ce47e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# Read .csv file from DeepLabCut\n",
        "path = \"2019-04-19_09-34-36cut0_30minDeepCut_resnet50_OpenFieldHighResApr8shuffle1_1030000.csv\"\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "# Clear the first two rows that are not values\n",
        "data = np.array(data[2:])\n",
        "\n",
        "# Convert string to floats\n",
        "data = data.astype(np.float)\n",
        "\n",
        "# Remove Likelihood columns, for testing purposes.\n",
        "# This will be replaced with our adaptive high pass filter function:\n",
        "# dlc_preprocess2.py\n",
        "i = [0,3,6,9,12,15,18]\n",
        "data = np.delete(data, i, 1)\n",
        "print('The shape of dataset after removing likelihoods:',data.shape)\n",
        "\n",
        "# Imagine if there are unequal sized arrays (30 seconds vs 1 hour)\n",
        "data2 = data[10000:]\n",
        "print('The shape of dataset 2, supposedly shorter:',data2.shape)\n",
        "\n",
        "# Create a 3D array for that (similar to cells for matrices)\n",
        "data1 = np.array((data,data2))\n",
        "print('After compiling the two datasets, the first row of dataset2 looks like:', data1[1][:, 1])\n",
        "data = data1\n",
        "\n",
        "# Working with just the first dataset, for example\n",
        "m = 0\n",
        "fpd=data[m][:,2:4] - data[m][:,4:6]\n",
        "print('Computed x and y difference between the two forepaws, for example, the first time point= ',fpd[0])\n",
        "\n",
        "cfp=np.vstack(((data[m][:,2]+data[m][:,4])/2,(data[m][:,3]+data[m][:,5])/2)).T\n",
        "print('Computed center forepaw x and y positions, for example, the first time point= ',cfp[0])\n",
        "\n",
        "\n",
        "# Getting EST time info for check points\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/EST5EDT /etc/localtime\n",
        "localtime = !date\n",
        "\n",
        "print('Check point, local current time:', str(localtime))\n",
        "\n",
        "cfpLen = len(cfp)\n",
        "cfp_pt = np.vstack(([cfp[:,0] - data[m][:,10],cfp[:,1] - data[m][:,11]])).T\n",
        "print('Center forepaw to tail-base:',cfp_pt[0])\n",
        "\n",
        "chp = np.vstack((((data[m][:,6]+data[m][:,8])/2),((data[m][:,7]+data[m][:,9])/2))).T\n",
        "print(\"Computed center hindpaw x and y positions, first time point = \", chp[0])\n",
        "\n",
        "chp_pt = np.vstack(([chp[:,0] - data[m][:,10],chp[:,1] - data[m][:,11]])).T\n",
        "print(\"Center hindpaw to tail-base:\", chp_pt[0])\n",
        "\n",
        "sn_pt = np.vstack(([data[m][:,0] - data[m][:,10],data[m][:,1] - data[m][:,11]])).T\n",
        "print(\"Snout to tail-base:\", sn_pt[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The shape of dataset after removing likelihoods: (108000, 12)\n",
            "The shape of dataset 2, supposedly shorter: (98000, 12)\n",
            "After compiling the two datasets, the first row of dataset2 looks like: [102.05613947 101.52682424 100.40078413 ...   8.52450204  10.16468036\n",
            "  10.1649425 ]\n",
            "Computed x and y difference between the two forepaws, for example, the first time point=  [41.61943966 17.41654015]\n",
            "Computed center forepaw x and y positions, for example, the first time point=  [456.64841804 575.09360766]\n",
            "Check point, local current time: ['Thu Feb 20 11:30:10 EST 2020']\n",
            "Center forepaw to tail-base: [ 60.8583723  112.99130201]\n",
            "Computed center hindpaw x and y positions, first time point =  [400.56650871 499.87675464]\n",
            "Center hindpaw to tail-base: [ 4.77646297 37.77444899]\n",
            "Snout to tail-base: [ 59.60507226 180.71323895]\n",
            "45.11666685816137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDuOh5x1b3up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e17eb1dd-e844-4fd9-96e3-8471bdeb07d7"
      },
      "source": [
        "fpd_norm_smth[m] = np.cumsum(fpd_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "print(fpd_norm_smth[0])\n",
        "sn_cfp_norm_smth[m]=np.cumsum(sn_pt_norm - cfp_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "sn_chp_norm_smth[m]=np.cumsum(sn_pt_norm - chp_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "sn_pt_norm_smth[m]=np.cumsum(sn_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "\n",
        "# sn_pt_ang = np.zeros(len(data[m]))\n",
        "# sn_disp = np.zeros(len(data[m]))\n",
        "# pt_disp = np.zeros(len(data[m]))\n",
        "\n",
        "# for k in range(0,len(data[m]) - 1):\n",
        "#     b_3d = np.hstack([sn_pt[k + 1,:],0])\n",
        "#     a_3d = np.hstack([sn_pt[k,:],0])\n",
        "#     c = np.cross(b_3d,a_3d)\n",
        "#     sn_pt_ang[k] = np.dot(np.dot(np.sign(c[2]),180)/np.pi , math.atan2(np.linalg.norm(c),np.dot(sn_pt[k,:],sn_pt[k + 1,:])))\n",
        "#     sn_disp[k] = np.linalg.norm(data[m][k + 1,0:2] - data[m][k,0:2])\n",
        "#     pt_disp[k] = np.linalg.norm(data[m][k + 1,10:12] - data[m][k,10:12])\n",
        "# print(b_3d,a_3d,c)\n",
        "# print(sn_pt_ang)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[143.56969738 -89.58016491   0.        ] [143.65810978 -89.42796957   0.        ] [ 0.          0.         29.77063584]\n",
            "[-1.56935919 -3.5390935  -1.59733529 ...  1.1359397   0.05956613\n",
            "  0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RvbmBJmeI_B",
        "colab_type": "code",
        "outputId": "d602ed3b-57d6-4271-b0b8-19a14aa3defc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "## First half of the code, computing and compiling features necessary for t-SNE and GMM\n",
        "print('Obtaining features from dataset... \\n')\n",
        "for m in range(len(data)):\n",
        "        ## Obtain features, 2 physical features and 5 time-varying signals\n",
        "        #clear('fpd_norm','cfp_pt_norm','chp_pt_norm','sn_pt_norm','sn_pt_ang','sn_disp','pt_disp')\n",
        "        dataRange = len(data[m])\n",
        "        fpd = data[m][:,2:4] - data[m][:,4:6]\n",
        "        cfp = np.vstack(((data[m][:,2]+data[m][:,4])/2,(data[m][:,3]+data[m][:,5])/2)).T\n",
        "        cfpLen = len(cfp)\n",
        "        cfp_pt = np.vstack(([cfp[:,0]-data[m][:,10],cfp[:,1]-data[m][:,11]])).T\n",
        "        chp = np.vstack((((data[m][:,6]+data[m][:,8])/2),((data[m][:,7]+data[m][:,9])/2))).T\n",
        "        chp_pt = np.vstack(([chp[:,0] - data[m][:,10],chp[:,1] - data[m][:,11]])).T\n",
        "        sn_pt = np.vstack(([data[m][:,0] - data[m][:,10],data[m][:,1] - data[m][:,11]])).T\n",
        "\n",
        "        #Initialize arrays for distance norms\n",
        "        fpd_norm = np.zeros(len(data[m]))\n",
        "        cfp_pt_norm = np.zeros(len(data[m]))\n",
        "        chp_pt_norm = np.zeros(len(data[m]))\n",
        "        sn_pt_norm = np.zeros(len(data[m]))\n",
        "        for i in range(1,len(data[m])):\n",
        "            fpd_norm[i] = np.array(np.linalg.norm(data[m][i,2:4] - data[m][i,4:6]))\n",
        "            cfp_pt_norm[i] = np.linalg.norm(cfp_pt[i,:])\n",
        "            chp_pt_norm[i] = np.linalg.norm(chp_pt[i,:])\n",
        "            sn_pt_norm[i] = np.linalg.norm(sn_pt[i,:])\n",
        "        fpd_norm_smth[m]=np.cumsum(fpd_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "        sn_cfp_norm_smth[m]=np.cumsum(sn_pt_norm - cfp_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "        sn_chp_norm_smth[m]=np.cumsum(sn_pt_norm - chp_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "        sn_pt_norm_smth[m]=np.cumsum(sn_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "        \n",
        "        #Initialize arrays for angle norms\n",
        "        sn_pt_ang = np.zeros(len(data[m]))\n",
        "        sn_disp = np.zeros(len(data[m]))\n",
        "        pt_disp = np.zeros(len(data[m]))\n",
        "        for k in range(0,len(data[m]) - 1):\n",
        "            b_3d = np.hstack([sn_pt[k + 1,:],0])\n",
        "            a_3d = np.hstack([sn_pt[k,:],0])\n",
        "            c = np.cross(b_3d,a_3d)\n",
        "            sn_pt_ang[k] = np.dot(np.dot(np.sign(c[2]),180)/np.pi , math.atan2(np.linalg.norm(c),np.dot(sn_pt[k,:],sn_pt[k + 1,:])))\n",
        "            sn_disp[k] = np.linalg.norm(data[m][k + 1,0:2] - data[m][k,0:2])\n",
        "            pt_disp[k] = np.linalg.norm(data[m][k + 1,10:12] - data[m][k,10:12])\n",
        "        sn_pt_ang_smth[m]=np.cumsum(sn_pt_ang,np.hstack([smth_hstry,smth_futr]))\n",
        "        sn_disp_smth[m]=np.cumsum(sn_disp,np.hstack([smth_hstry,smth_futr]))\n",
        "        pt_disp_smth[m]=np.cumsum(pt_disp,np.hstack([smth_hstry,smth_futr]))\n",
        "\n",
        "        ## Collate 7 features. We will reduce the dimensions using the KL-distance in a stochastic process.\n",
        "        feats[m]=np.vstack([[sn_cfp_norm_smth[m][:,2:]],[sn_chp_norm_smth[m][:,2:]],\n",
        "            [fpd_norm_smth[m][:,2:]],[sn_pt_norm_smth[m][:,2:]],[sn_pt_ang_smth[m][:,1:]],\n",
        "            [sn_disp_smth[m][:,1:]],[pt_disp_smth[m][:,1:]]]).T\n",
        "\n",
        "# Getting EST time info for check points\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/EST5EDT /etc/localtime\n",
        "localtime = !date\n",
        "\n",
        "print('Check point, local current time:', str(localtime))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[629.5991118  619.60145244 620.00729704 ...   8.52450204  10.16468036\n",
            "  10.1649425 ]\n",
            "(108000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beQZa_gCkod-",
        "colab_type": "code",
        "outputId": "561d8668-4e1b-4f5c-df2d-c586821a3ea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "if comp == 1:\n",
        "   f_10fps=[]\n",
        "   \n",
        "for n in range(1,len(feats)).reshape(-1):\n",
        "  feats1=[]\n",
        "  for k in range(fps / 10,len(feats[n]),fps / 10).reshape(-1):\n",
        "    feats1[:,end() + 1]=np.hstack([[np.mean(feats[n][1:5,range(k - fps / 10 + 1,k)],2)],\n",
        "    [sum(feats[n][5:8,range(k - fps / 10 + 1,k)],2)]])\n",
        "    if comp == 1:\n",
        "      f_10fps=np.concatenate(2,f_10fps,feats1)\n",
        "    else:\n",
        "      f_10fps[n]=feats1\n",
        "    if len(f_10fps[n]) < 15000:\n",
        "      p=50\n",
        "    else:\n",
        "    p=400\n",
        "    np.random.seed(0)\n",
        "    tsne_feats=[]\n",
        "    print('Running individual datasets through t-SNE collapsing the 7 features onto 3 action space coordinates... \\n')\n",
        "    tsne_feats=TSNE(f_10fps[n][:,:].transpose,'Standardize',true,'Perplexity',p,'NumDimensions',3)\n",
        "    # Run a Gaussian Mixture Model Expectation Maximization to group the t-SNE clusters\n",
        "    # may need to change with GaussianMixture imported from sklearn.mixture.\n",
        "    X=tsne_feats.transpose\n",
        "    k=copy.copy(kclass)\n",
        "    [grp[n],model[n],llh[n]]=GMM(X,k,it,nargout=3)\n",
        "    print('TADA! \\n')\n",
        "    # Create colormap, and create 3d scatter plot, may need to change for python matplotlib\n",
        "    cmap=hsv(len(np.unique(grp[n])))\n",
        "    for g in range(1,len(np.unique(grp[n]))).reshape(-1):\n",
        "      bsoid_fig[n]=plt.scatter(tsne_feats[grp[n] == g,1],tsne_feats[grp[n] == g,2],tsne_feats[grp[n] == g,3],15,'filled')\n",
        "      bsoid_fig[n].MarkerFaceColor = copy(cmap[g,:])\n",
        "      plt.legend(str(range(1,len(np.unique(grp[n])))))\n",
        "    if comp == 1:\n",
        "      if length(f_10fps) < 15000:\n",
        "        p=50\n",
        "      else:\n",
        "        p=400\n",
        "    np.random.seed(0)\n",
        "    tsne_feats=[]\n",
        "    print('Running the compiled data through t-SNE collapsing the 7 features onto 3 action space coordinates... \\n')\n",
        "    tsne_feats=TSNE(f_10fps[:,:].transpose,'Standardize',true,'Perplexity',p,'NumDimensions',3)\n",
        "    X=tsne_feats.transpose\n",
        "    k=copy.copy(kclass)\n",
        "    [grp,model,llh,maxll]=GMM(X,k,it,nargout=4)\n",
        "    fprintf('TADA! \\n')\n",
        "    cmap=hsv(len(np.unique(grp)))\n",
        "    for g in range(1,len(np.unique(grp))).reshape(-1):\n",
        "      bsoid_fig=scatter3(tsne_feats[grp == g,1],tsne_feats[grp == g,2],tsne_feats[grp == g,3],15,'filled')\n",
        "      bsoid_fig.MarkerFaceColor = copy.copy(cmap[g,:])\n",
        "      plt.legend(string(range(1,len(np.unique(grp)))))\n",
        "\n",
        "\n",
        "# Getting EST time info for check points\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/EST5EDT /etc/localtime\n",
        "localtime = !date\n",
        "\n",
        "print('Check point, local current time:', str(localtime))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-52d522e66bba>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    p=400\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vatTnUgsmCPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# After we fixed the individual sections above, replace it within this function.\n",
        "\n",
        "def bsoid_gmm(data,fps,comp,smth_hstry,smth_fut,kclass,it,*args,**kwargs):\n",
        "    varargin = bsoid_gmm.varargin\n",
        "    nargin = bsoid_gmm.nargin\n",
        "\n",
        "    #BSOID_GMM  Behavioral Segmentation of Open-Field Behavior based on Gaussian Mixture Models (GMM) in DeepLabCut. This unsupervised learning algorithm\n",
        "#              parses out action groups based on statistically different feature distribution.\n",
        "#   \n",
        "#   [FEATS,TSNE_FEATS,GRP,LLH,BSOID_FIG] = BSOID_GMM(DATA,FPS,COMP,SMTH_HSTRY,SMTH_FUTR,KCLASS,IT) outputs classified behaviors based on DeepLabCut analysis\n",
        "    \n",
        "    #   INPUTS:\n",
        "#   DATA    6-body parts (x,y) matrix outlining the tetrapod animal over time videotaped from the bottom looking up. Rows represents time.\n",
        "#           Columns 1 & 2 tracks snout; columns 3 to 6 tracks the two front paws; columns 7 to 10 tracks the two hind paws;\n",
        "#           columns 11 & 12 tracks the base of the tail. Tested on tracking data generated by DeepLabCut 2.0.\n",
        "#   FPS    Rounded frame rate, can use VideoReader/ffmpeg(linux command) to automatically detect the input video fps.\n",
        "#   COMP    If you desire 1 classifier built on multiple animals, set this parameter to 1; Otherwise, this will build individual classifier/.csv file.\n",
        "#           Default is 1. \n",
        "#   SMTH_HSTRY    BOXCAR smoothing using number of frames from before. Default ~40ms before.\n",
        "#   SMTH_FUTR    BOXCAR smoothing using number of frames from after. Default ~40ms after.\n",
        "#   KCLASS    Maximum number of classes that the Gaussian Mixture Model will try to parse out. Default 30.\n",
        "#   IT    Number of iterations to potentially find global, instead of local optimum. Default 20.\n",
        "    \n",
        "    #   OUTPUTS:\n",
        "#   F_10FPS    Compiled features that were used to cluster, 10fps temporal resolution.\n",
        "#   TSNE_FEATS    A 3-dimensional space where 7 features are embedded using t-Distributed Stochastic Neighbor Embedding. The perplexity (p) here can be\n",
        "#                 modified to the user liking if needed.                 \n",
        "#   GRP    Statistically different groups of actions based on data. Output is 10Hz matching F_10FPS and TSNE_FEATS.\n",
        "#   LLH    Log-likelihood to see if the EM algorithm converged.\n",
        "#   BSOID_FIG    Graph showing the how Gaussian Mixture Models grouped data points in the 3D action space.\n",
        "    \n",
        "    #   EXAMPLES:\n",
        "#   clear data;\n",
        "#   load MsInOpenField.mat\n",
        "#   [feats,f_10fps,tsne_feats,grp] = bsoid_gmm(data,60,1);\n",
        "    \n",
        "    #   clear data;\n",
        "#   data{1} = [rand(10000,3),randi([1 4],10000,3),randi([-5 5],10000,3),randn(10000,3)];\n",
        "#   fps = 60;\n",
        "#   [feats,tsne_feats,grp,llh,bsoid_fig] = bsoid(data,fps,0,2,1,8);\n",
        "    \n",
        "    #   clear data;\n",
        "#   data{1} = [rand(1000,12);randn(1000,12);randi(1000,12)];\n",
        "#   data{2} = [rand(1000,12);randn(1000,12);randi(1000,12)];\n",
        "#   fps = 30;\n",
        "#   [feats,tsne_feats,grp,llh,bsoid_fig] = bsoid(data,fps,1);\n",
        "#   \n",
        "#   clear data; load fisheriris.mat; \n",
        "#   data{1} = [meas,meas,meas]; \n",
        "#   fps = 10;\n",
        "#   [feats,tsne_feats,grp,llh,bsoid_fig] = bsoid(data,fps,0,0,0,3);\n",
        "    \n",
        "    #   Created by Alexander Hsu, Date: 070819\n",
        "#   Contact ahsu2@andrew.cmu.edu\n",
        "    \n",
        "    if nargin < 2:\n",
        "        error('Please input dataset AND frame rate!')\n",
        "    \n",
        "    if nargin < 3:\n",
        "        comp=1\n",
        "    \n",
        "    if nargin < 5:\n",
        "        smth_hstry=round(0.05 / (1 / fps)) - 1\n",
        "        smth_futr=round(0.05 / (1 / fps)) - 1\n",
        "    \n",
        "    if nargin < 6:\n",
        "        kclass=30\n",
        "    \n",
        "    if nargin < 7:\n",
        "        it=20\n",
        "    \n",
        "    print('Obtaining features from dataset... \\n')\n",
        "    for m in range(len(data)).reshape(-1):\n",
        "        ## Obtain features, 2 physical features and 5 time-varying signals\n",
        "        #clear('fpd_norm','cfp_pt_norm','chp_pt_norm','sn_pt_norm','sn_pt_ang','sn_disp','pt_disp')\n",
        "        dataRange = len(data[m])\n",
        "        fpd=data[m][:,2:4] - data[m][:,4:6]\n",
        "        cfp=[sum(data[m][2],data[m][4]/2),sum(data[m][3],data[m][5])/2]\n",
        "        cfpLen = len(cfp)\n",
        "        cfp_pt=np.hstack([cfp[:,1] - data[m][:,11],cfp[:,2] - data[m][:,12]])\n",
        "        chp=np.hstack([np.mean(np.hstack([data[m][:,7],data[m][:,9],2])),np.mean(np.hstack([data[m][:,8],data[m][:,10]]),2)])\n",
        "        chp_pt=np.hstack([chp[:,1] - data[m][:,11],chp[:,2] - data[m][:,12]])\n",
        "        sn_pt=np.hstack([data[m][:,1] - data[m][:,11],data[m][:,2] - data[m][:,12]])\n",
        "        for i in range(1,len(data[m])).reshape(-1):\n",
        "            fpd_norm[i]=np.linalg.norm(data[m](i,range(2,4)) - data[m](i,range(4,6)))\n",
        "            cfp_pt_norm[i]=np.linalg.norm(cfp_pt[i,:])\n",
        "            chp_pt_norm[i]=np.linalg.norm(chp_pt[i,:])\n",
        "            sn_pt_norm[i]=np.linalg.norm(sn_pt[i,:])\n",
        "        fpd_norm_smth[m]=np.cumsum(fpd_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "        sn_cfp_norm_smth[m]=np.cumsum(sn_pt_norm - cfp_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "        sn_chp_norm_smth[m]=np.cumsum(sn_pt_norm - chp_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "        sn_pt_norm_smth[m]=np.cumsum(sn_pt_norm,np.hstack([smth_hstry,smth_futr]))\n",
        "        for k in arange(1,len(data[m]) - 1).reshape(-1):\n",
        "            b_3d=np.hstack([sn_pt[k + 1,:],0])\n",
        "            a_3d=np.hstack([sn_pt[k,:],0])\n",
        "            c=np.cross(b_3d,a_3d)\n",
        "            sn_pt_ang[k]=np.dot(np.dot(np.sign(c[3]),180) / np.pi,math.atan2(np.linalg.norm(c),np.dot(sn_pt[k,:],sn_pt[k + 1,:])))\n",
        "            sn_disp[k]=np.linalg.norm(data[m][k + 1,1:3] - data[m][k,1:3])\n",
        "            pt_disp[k]=np.linalg.norm(data[m][k + 1,11:13] - data[m][k,11:13])\n",
        "        sn_pt_ang_smth[m]=np.cumsum(sn_pt_ang,np.hstack([smth_hstry,smth_futr]))\n",
        "        sn_disp_smth[m]=np.cumsum(sn_disp,np.hstack([smth_hstry,smth_futr]))\n",
        "        pt_disp_smth[m]=np.cumsum(pt_disp,np.hstack([smth_hstry,smth_futr]))\n",
        "\n",
        "        ## Collate 7 features. We will reduce the dimensions using the KL-distance in a stochastic process.\n",
        "        feats[m]=np.hstack([[sn_cfp_norm_smth[m][:,2:]],[sn_chp_norm_smth[m][:,2:]],\n",
        "            [fpd_norm_smth[m][:,2:]],[sn_pt_norm_smth[m][:,2:]],[sn_pt_ang_smth[m][:,1:]],\n",
        "            [sn_disp_smth[m][:,1:]],[pt_disp_smth[m][:,1:]]])\n",
        "    \n",
        "    if comp == 1:\n",
        "        f_10fps=[]\n",
        "    \n",
        "    for n in range(1,len(feats)).reshape(-1):\n",
        "        feats1=[]\n",
        "        for k in range(fps / 10,len(feats[n]),fps / 10).reshape(-1):\n",
        "            feats1[:,end() + 1]=np.hstack([[np.mean(feats[n][1:5,range(k - fps / 10 + 1,k)],2)],\n",
        "                [sum(feats[n][5:8,range(k - fps / 10 + 1,k)],2)]])\n",
        "        if comp == 1:\n",
        "            f_10fps=np.concatenate(2,f_10fps,feats1)\n",
        "        else:\n",
        "            f_10fps[n]=feats1\n",
        "            if len(f_10fps[n]) < 15000:\n",
        "                p=50\n",
        "            else:\n",
        "                p=400\n",
        "            #error(sprintf('Reduce the dataset, might take too long to run... \\nHowever, if you think you know what you are doing, edit bsoid_gmm and set perplexity value yourself :D \\n'))\n",
        "            ## For reproducibility\n",
        "            rng('default')\n",
        "            tsne_feats=[]\n",
        "            print('Running individual datasets through t-SNE collapsing the 7 features onto 3 action space coordinates... \\n')\n",
        "            tsne_feats=TSNE(f_10fps[n][:,:].transpose,'Standardize',true,'Perplexity',p,'NumDimensions',3)\n",
        "            ## Run a Gaussian Mixture Model Expectation Maximization to group the t-SNE clusters\n",
        "            X=tsne_feats.transpose\n",
        "            k=copy.copy(kclass)\n",
        "            (grp[n],model[n],llh[n])=GMM(X,k,it,nargout=3)\n",
        "            print('TADA! \\n')\n",
        "            cmap=hsv(len(np.unique(grp[n])))\n",
        "# bsoid_gmm.m:155\n",
        "            for g in range(1,len(np.unique(grp[n]))).reshape(-1):\n",
        "                bsoid_fig[n]=plt.scatter(tsne_feats[grp[n] == g,1],tsne_feats[grp[n] == g,2],tsne_feats[grp[n] == g,3],15,'filled')\n",
        "# bsoid_gmm.m:158\n",
        "                bsoid_fig[n].MarkerFaceColor = copy(cmap[g,:])\n",
        "# bsoid_gmm.m:159\n",
        "            plt.legend(str(range(1,len(np.unique(grp[n])))))\n",
        "    \n",
        "    if comp == 1:\n",
        "        if length(f_10fps) < 15000:\n",
        "            p=50\n",
        "        else:\n",
        "            p=400\n",
        "# bsoid_gmm.m:196\n",
        "            #error(sprintf('Reduce the dataset, might take too long to run... \\nHowever, if you think you know what you are doing, edit bsoid_gmm and set perplexity value yourself :D \\n'))\n",
        "        ## For reproducibility\n",
        "        np.random.seed(0)\n",
        "        tsne_feats=[]\n",
        "# bsoid_gmm.m:200\n",
        "        print('Running the compiled data through t-SNE collapsing the 7 features onto 3 action space coordinates... \\n')\n",
        "        tsne_feats=TSNE(f_10fps[:,:].transpose,'Standardize',true,'Perplexity',p,'NumDimensions',3)\n",
        "        X=tsne_feats.transpose\n",
        "        k=copy.copy(kclass)\n",
        "        (grp,model,llh,maxll)=GMM(X,k,it,nargout=4)\n",
        "        fprintf('TADA! \\n')\n",
        "        cmap=hsv(len(np.unique(grp)))\n",
        "# bsoid_gmm.m:207\n",
        "        for g in range(1,len(np.unique(grp))).reshape(-1):\n",
        "            bsoid_fig=scatter3(tsne_feats[grp == g,1],tsne_feats[grp == g,2],tsne_feats[grp == g,3],15,'filled')\n",
        "# bsoid_gmm.m:210\n",
        "            bsoid_fig.MarkerFaceColor = copy.copy(cmap[g,:])\n",
        "# bsoid_gmm.m:211\n",
        "        plt.legend(string(range(1,len(np.unique(grp)))))\n",
        "    \n",
        "    \n",
        "    return f_10fps,tsne_feats,grp,llh,bsoid_fig"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}